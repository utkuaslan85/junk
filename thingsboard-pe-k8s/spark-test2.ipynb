{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0404cf-3471-41b7-be50-cc964456e5b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T11:14:48.759965Z",
     "iopub.status.busy": "2021-10-12T11:14:48.759569Z",
     "iopub.status.idle": "2021-10-12T11:14:48.907626Z",
     "shell.execute_reply": "2021-10-12T11:14:48.907125Z",
     "shell.execute_reply.started": "2021-10-12T11:14:48.759937Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from confluent_kafka import DeserializingConsumer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroDeserializer\n",
    "from confluent_kafka.serialization import StringDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9d7988-1913-428e-99c6-94fa5a0a2595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T11:18:53.460256Z",
     "iopub.status.busy": "2021-10-12T11:18:53.459895Z",
     "iopub.status.idle": "2021-10-12T11:18:53.466516Z",
     "shell.execute_reply": "2021-10-12T11:18:53.465373Z",
     "shell.execute_reply.started": "2021-10-12T11:18:53.460224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read schema from file\n",
    "with open('schema3.txt', 'r') as f:\n",
    "    schema_str = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29b0bfd-34e0-4eff-9a23-21dfc2d587ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672313302.0463\n",
      "{'ts': 1672313289395, 'data_key': 'dummy_humidity', 'data_value': '67.36'}\n",
      "{'ts': 1672313289395, 'data_key': 'dummy_location', 'data_value': 'xjbm84nkttaknwfdpldi'}\n",
      "{'ts': 1672313289394, 'data_key': 'dummy_temp', 'data_value': '20'}\n",
      "{'ts': 1672313289396, 'data_key': 'dummy_bool', 'data_value': 'false'}\n",
      "{'ts': 1672313294393, 'data_key': 'dummy_bool', 'data_value': 'false'}\n",
      "{'ts': 1672313294393, 'data_key': 'dummy_location', 'data_value': 'hpgj4fciimna3pvnp14i'}\n",
      "{'ts': 1672313294392, 'data_key': 'dummy_temp', 'data_value': '21'}\n",
      "{'ts': 1672313294392, 'data_key': 'dummy_temp', 'data_value': '21'}\n",
      "{'ts': 1672313299402, 'data_key': 'dummy_bool', 'data_value': 'true'}\n",
      "{'ts': 1672313299402, 'data_key': 'dummy_location', 'data_value': 'qk0d0sfbkiragow7y14i'}\n"
     ]
    }
   ],
   "source": [
    "print(time.time())\n",
    "topic = \"tb-kafka-avro8\"\n",
    "\n",
    "schema_registry_conf = {\"url\": \"http://10.105.144.163:8085\"}\n",
    "\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)\n",
    "\n",
    "avro_deserializer = AvroDeserializer(schema_registry_client, schema_str)\n",
    "\n",
    "string_deserializer = StringDeserializer('utf_8')\n",
    "\n",
    "consumer_conf = {'bootstrap.servers': \"10.102.117.121:9092\",\n",
    "                 'key.deserializer': string_deserializer,\n",
    "                 'value.deserializer': avro_deserializer,\n",
    "                 'group.id': \"test\",\n",
    "                 'auto.offset.reset': \"latest\"\n",
    "                }\n",
    "\n",
    "consumer = DeserializingConsumer(consumer_conf)\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < 10:\n",
    "    i+=1\n",
    "    try:\n",
    "        # SIGINT can't be handled when polling, limit timeout to 1 second.\n",
    "        msg = consumer.poll(1.0)\n",
    "        if msg is None:\n",
    "            print(\"none\")\n",
    "            continue\n",
    "        \n",
    "        if msg is not None:\n",
    "            print(msg.value())\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db66dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello():\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb9b5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "hello()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b67cac-14d2-4901-b67b-d606ae807ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T08:08:09.713350Z",
     "iopub.status.busy": "2021-10-12T08:08:09.712292Z",
     "iopub.status.idle": "2021-10-12T08:08:09.720054Z",
     "shell.execute_reply": "2021-10-12T08:08:09.719112Z",
     "shell.execute_reply.started": "2021-10-12T08:08:09.713296Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# s3 params\n",
    "with open('s3_params.txt', 'r') as f:\n",
    "    s3_params = json.loads(f.read())\n",
    "s3_key = s3_params['access-key']\n",
    "s3_secret = s3_params['secret-key']\n",
    "s3_url = s3_params['endpoint_url']\n",
    "s3_binance_cred_path = s3_params['cred_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ee2a6-9827-4bec-ab3d-95ef0331e3ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T08:44:33.756811Z",
     "iopub.status.busy": "2021-10-12T08:44:33.756418Z",
     "iopub.status.idle": "2021-10-12T08:44:33.761562Z",
     "shell.execute_reply": "2021-10-12T08:44:33.760886Z",
     "shell.execute_reply.started": "2021-10-12T08:44:33.756781Z"
    }
   },
   "outputs": [],
   "source": [
    "from s3fs.core import S3FileSystem\n",
    "# s3fs client\n",
    "s3 = S3FileSystem(\n",
    "     anon=False,\n",
    "     key=s3_key,\n",
    "     secret=s3_secret,\n",
    "     use_ssl=False,\n",
    "     client_kwargs={'endpoint_url': s3_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a869444-19ab-49d5-8d29-29327c582a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T08:52:40.758423Z",
     "iopub.status.busy": "2021-10-12T08:52:40.757995Z",
     "iopub.status.idle": "2021-10-12T08:52:40.766661Z",
     "shell.execute_reply": "2021-10-12T08:52:40.766127Z",
     "shell.execute_reply.started": "2021-10-12T08:52:40.758386Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "config = {\n",
    "    \"spark.kubernetes.namespace\": \"spark\",\n",
    "    \"spark.kubernetes.container.image\": \"localhost:32000/spark:3.1.2-hadoop-3.2.0-aws\",\n",
    "    \"spark.executor.instances\": \"1\",\n",
    "    \"spark.executor.memory\": \"1g\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.driver.blockManager.port\": \"7777\",\n",
    "    \"spark.driver.port\": \"2222\",\n",
    "    \"spark.driver.host\": \"jupyter.spark.svc.cluster.local\",\n",
    "    \"spark.driver.bindAddress\": \"0.0.0.0\",\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": s3_url,\n",
    "    \"spark.hadoop.fs.s3a.access.key\": s3_key,\n",
    "    \"spark.hadoop.fs.s3a.secret.key\": s3_secret,\n",
    "    \"spark.hadoop.fs.s3a.connection.ssl.enabled\": \"false\",\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": \"true\",\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.hadoop.com.amazonaws.services.s3.enableV4\": \"true\",\n",
    "    \"spark.hadoop.fs.s3a.aws.credentials.provider\": \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\",\n",
    "    \"spark.hadoop.fs.s3a.committer.name\": \"directory\",\n",
    "    \"spark.sql.sources.commitProtocolClass\": \"org.apache.spark.internal.io.cloud.PathOutputCommitProtocol\",\n",
    "    \"spark.sql.parquet.output.committer.class\": \"org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter\"\n",
    "}\n",
    "\n",
    "def get_spark_session(app_name: str, conf: SparkConf):\n",
    "    conf.setMaster(\"k8s://https://kubernetes.default.svc.cluster.local\")\n",
    "    for key, value in config.items():\n",
    "        conf.set(key, value)    \n",
    "    return SparkSession.builder.appName(app_name).config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbd96c-7548-4531-9c05-7f0eeb1cf4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T08:52:42.358051Z",
     "iopub.status.busy": "2021-10-12T08:52:42.357509Z",
     "iopub.status.idle": "2021-10-12T08:53:40.875229Z",
     "shell.execute_reply": "2021-10-12T08:53:40.874481Z",
     "shell.execute_reply.started": "2021-10-12T08:52:42.358008Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = get_spark_session(\"aws_localstack\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a1a3d-c059-473a-8768-b32738d9bf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df = spark.read.csv('s3a://data/test/BTCUSDT_MinuteBars.csv', header=True)\n",
    "    df.printSchema()\n",
    "    print(df.count())\n",
    "except Exception as exp:\n",
    "    print(exp)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e42d5-4b40-48da-82c3-691d22277cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T08:53:51.182412Z",
     "iopub.status.busy": "2021-10-12T08:53:51.181938Z",
     "iopub.status.idle": "2021-10-12T08:54:11.681379Z",
     "shell.execute_reply": "2021-10-12T08:54:11.680898Z",
     "shell.execute_reply.started": "2021-10-12T08:53:51.182367Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = get_spark_session(\"localstack\", conf)\n",
    "\n",
    "try:\n",
    "    df = spark.read.parquet('s3a://data/test/test.parquet/')\n",
    "    df.printSchema()\n",
    "    print(df.count())\n",
    "except Exception as exp:\n",
    "    print(exp)\n",
    "\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91bbb5-61c6-402f-b93e-acf82782809a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T08:57:10.030191Z",
     "iopub.status.busy": "2021-10-12T08:57:10.029925Z",
     "iopub.status.idle": "2021-10-12T08:57:10.075196Z",
     "shell.execute_reply": "2021-10-12T08:57:10.074255Z",
     "shell.execute_reply.started": "2021-10-12T08:57:10.030167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from s3fs.core import S3FileSystem\n",
    "from pyarrow import Table, parquet as pq\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "def to_df(data: List[Dict[str, Any]]) -> DataFrame:                                                                                                         \n",
    "    df = DataFrame()\n",
    "    for item in data:\n",
    "        indexes = []\n",
    "        values = []\n",
    "        for k, v in item.items():\n",
    "            indexes.append(k)\n",
    "            values.append(v)\n",
    "        df = df.append(Series(values, index=indexes), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# s3fs client\n",
    "fs = S3FileSystem(\n",
    "     anon=False,\n",
    "     key=s3_key,\n",
    "     secret=s3_secret,\n",
    "     use_ssl=False,\n",
    "     client_kwargs={'endpoint_url': s3_url})\n",
    "\n",
    "path_to_s3_object = \"s3://data/test/test.parquet\"\n",
    "\n",
    "data = [\n",
    "  {\n",
    "    \"hoge\": 1,\n",
    "    \"foo\": \"blah\",\n",
    "  },\n",
    "  {\n",
    "    \"boo\": \"test\",\n",
    "    \"bar\": 123,\n",
    "  },\n",
    "]\n",
    "df = to_df(data)\n",
    "pq.write_to_dataset(\n",
    "    Table.from_pandas(df),\n",
    "    path_to_s3_object,\n",
    "    filesystem=fs,\n",
    "    use_dictionary=True,\n",
    "    #compression=\"snappy\",\n",
    "    version=\"2.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c52e7-6cd3-48c1-81f5-8d2e80136c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic = \"avro-test\"\n",
    "\n",
    "schema_registry_conf = {'url': 'http://schema-registry.kafka.svc.cluster.local:8085'}\n",
    "\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)\n",
    "\n",
    "avro_deserializer = AvroDeserializer(schema_registry_client, schema_str)\n",
    "\n",
    "string_deserializer = StringDeserializer('utf_8')\n",
    "\n",
    "consumer_conf = {'bootstrap.servers': 'kafka.kafka.svc.cluster.local:9092',\n",
    "                    'key.deserializer': string_deserializer,\n",
    "                    'value.deserializer': avro_deserializer,\n",
    "                    'group.id': \"test\",\n",
    "                    'auto.offset.reset': \"earliest\"}\n",
    "\n",
    "consumer = DeserializingConsumer(consumer_conf)\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # SIGINT can't be handled when polling, limit timeout to 1 second.\n",
    "        msg = consumer.poll(1.0)\n",
    "        print(msg.value())\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "consumer.close()\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"AvroDeserializingProducer\")\n",
    "    parser.add_argument('-b', dest=\"bootstrap_servers\",\n",
    "                        default=\"kafka.kafka.svc.cluster.local:9092\", help=\"Bootstrap servers\")\n",
    "    parser.add_argument('-r', dest=\"schema_registry\",\n",
    "                        default=\"http://schema-registry.kafka.svc.cluster.local:8085\", help=\"Schema registry url\")\n",
    "    parser.add_argument('-t', dest=\"topic\", default=\"test\", help=\"Topic\")\n",
    "    parser.add_argument('-s', dest=\"symbol\", default=\"BTCUSDT\", help=\"Symbol\")\n",
    "    parser.add_argument('-g', dest=\"group\", default=\"test\", help=\"Consumer group\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118248d-b411-4ac5-9d6e-5d92725408f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic = \"test\"\n",
    "\n",
    "schema_registry_conf = {\"url\": \"http://schema-registry.kafka.svc.cluster.local:8085\"}\n",
    "\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)\n",
    "\n",
    "avro_deserializer = AvroDeserializer(schema_registry_client, schema_str)\n",
    "\n",
    "string_deserializer = StringDeserializer('utf_8')\n",
    "\n",
    "consumer_conf = {'bootstrap.servers': \"kafka.kafka.svc.cluster.local:9092\",\n",
    "                 'key.deserializer': string_deserializer,\n",
    "                 'value.deserializer': avro_deserializer,\n",
    "                 'group.id': \"test\",\n",
    "                 'auto.offset.reset': \"earliest\"}\n",
    "\n",
    "consumer = DeserializingConsumer(consumer_conf)\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # SIGINT can't be handled when polling, limit timeout to 1 second.\n",
    "        msg = consumer.poll(1.0)\n",
    "        print(msg.value())\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "consumer.close()\n",
    "\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "from s3fs.core import S3FileSystem\n",
    "from pyarrow import Table, parquet as pq\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "def to_df(data: List[Dict[str, Any]]) -> DataFrame:                                                                                                         \n",
    "    df = DataFrame()\n",
    "    for item in data:\n",
    "        indexes = []\n",
    "        values = []\n",
    "        for k, v in item.items():\n",
    "            indexes.append(k)\n",
    "            values.append(v)\n",
    "        df = df.append(Series(values, index=indexes), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# s3fs client\n",
    "fs = S3FileSystem(\n",
    "     anon=False,\n",
    "     key=s3_key,\n",
    "     secret=s3_secret,\n",
    "     use_ssl=False,\n",
    "     client_kwargs={'endpoint_url': s3_url})\n",
    "\n",
    "path_to_s3_object = \"s3://data/test/test.parquet\"\n",
    "\n",
    "data = [\n",
    "  {\n",
    "    \"hoge\": 1,\n",
    "    \"foo\": \"blah\",\n",
    "  },\n",
    "  {\n",
    "    \"boo\": \"test\",\n",
    "    \"bar\": 123,\n",
    "  },\n",
    "]\n",
    "df = to_df(data)\n",
    "pq.write_to_dataset(\n",
    "    Table.from_pandas(df),\n",
    "    path_to_s3_object,\n",
    "    filesystem=fs,\n",
    "    use_dictionary=True,\n",
    "    #compression=\"snappy\",\n",
    "    version=\"2.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d4091-78a6-438f-a4c1-3234714c170d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "86acff9bc8c19a5dd32b9c5fea9952c789b56aacb373472289479ffaa23e1c16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
